.. _chap-tutorial:

********
Tutorial
********

This chapter is a a tutorial in xSPDE functionality, giving a number of examples, and exercises. Not all the graphs generated by the scripts are included here, for space reasons. One can obtain many more graphs if desired, by generating more observables.

Vertical bars in the graphs are the step-size errors in time, calculated from setting :attr:`checks` to ``1``. These are automatically omitted when the relative errors are too small to be visible. In most cases, the default ranges and step-sizes are used to keep things simple. One can improve this accuracy by using more points, as shown in the first example, or by using more steps per point.

Upper and lower solid lines are due to sampling errors. This occurs where there is statistical noise, and requires a finite number of serial (``p.ensembles(2)``) or parallel (``p.ensembles(3)``) ensembles to calculate it. One can improve this by using more ensembles. Sub-ensemble averaging with multiple sub-ensembles is used to improve the accuracy of error estimates.

There are preset preferences for all the input parameters except the derivative function, which defines the equation that is simulated. Each example in the tutorial has exercises, which are very simple. However, they help to understand xSPDE conventions, and it is recommended to try them.

.. note::

    All the exercises, and some bonus examples, are given in the xSPDE ``Examples`` folder.


Wiener process
==============

Try increasing the time resolution and adding a heading to the random walk example in :ref:`chap-interactive`. 

This requires specifying the number of points using :attr:`points`. To name the simulation, use :attr:`name`, which is stored with your simulation data. The default option is to add this heading to each graph. If no header is wanted, type ``p.headers = 0``.

To run the xSPDE program after adding these inputs, click the *Run* icon on the Matlab editor bar.  This will run the xSPDE program, with default parameters where they are not specified in the inputs. You will see the following figure:

.. figure:: Figures/Wiener_2.*

    Increasing the Wiener process resolution and adding a header.

.. rubric:: Exercise

Add 100 samples and 100 serial ensemble trajectories. Does the mean equal zero within the sampling error bars?


Harmonic oscillator
===================

The next example is the stochastic harmonic oscillator with the initial condition that

.. math::

    a(0) = 1+v,

where

.. math::

    \left\langle v^{2}\right\rangle = 1

and the differential equation:

.. math::

    \dot{a}=ia+w(t).

Initial conditions and derivative
---------------------------------

First, make sure you type ``clear`` to clear the previous example. This is good practice for all the examples. The following parameters are needed to specify the harmonic oscillator with noise. By specifying return values in square brackets, the data is made available in the user data space:

::

    clear
    p.initial = @(rv,~) 1+rv;
    p.ensembles = [20,20];
    p.deriv = @(a,w,~) i*a + w;
    p.olabels = {'<a_1>'};
    xspde(p);
  
Here ``~`` indicates an unused input to a function, while ``i`` is the Matlab codes for the unit imaginary number, :math:`i`. The following graph is produced:

.. figure:: Figures/NoisySHO.*

    Simple harmonic oscillator amplitude

The plotted error-bars are suppressed, as they are too small to see, nor is there any header, since none was specified. The :func:`xsim` program reports an error summary, using the default number of points (51), for the sampling error and the step error.

This is an approximate upper bound on the overall integration error of the specified observable. It is calculated from comparing two solutions. In this case, the default estimates are obtained by comparing a coarse and fine step calculation at half the specified step-size. The difference between the fine result and the coarse result gives the step error estimate, which is usually very conservative. Sampling errors are estimated from statistics of stochastic results only when the higher level ensembles are used.

Comparisons with exact results
------------------------------

The stochastic equation has the mean solution:

.. math::

    \begin{aligned}
    \left\langle a\left(t\right)\right\rangle
        & = e^{it}\\
        & = \cos\left(t\right)+i\sin\left(t\right)
    \end{aligned}

To compare the calculated solution with this exact result, just tell the graphics program that you want a comparison, by editing the project file, and adding a comparison function.

This example uses the previous inputs, together with the comparison function itself (:attr:`compare`). All functions and data relating to observables are cell arrays, hence the curly brackets: ``compare{1}`` is the first element of an array of comparison functions that might be needed if there are many observables.

::

    p.compare{1} = @(t,~) cos(t);
    xspde(p);

With this input, xgraph gives the difference in the comparison as:

::

    -  Maximum comparison differences = 1.950535e-01

The actual error in this case is smaller than the error estimated using the sampling error estimates. However, the error-bars are very small. This is because in this case, the specified fine step-size is small enough to give excellent convergence.

Comparison graphs are also produced, including one of the relative errors:

.. figure:: Figures/NoisySHOCompareErrors.*

   Simple harmonic oscillator comparison graph: exact vs computed, with
   error-bars.

The reported summary data is consistent with the graphs, as expected. Note that one can obtain exactly the same result in the interaction picture, by using an imaginary linear coupling of :math:`i`, and a derivative term of zero. The code then reports a maximum step-size error of around :math:`\sim10^{-15}`, equal to the limit of IEEE arithmetic.

.. rubric:: Exercise

Add a linear decay of :math:`-a` to the differential equation, and modify the exact solution to suit, then replot. Is it exactly as you expected?


Kubo oscillator
===============

The next example is more interesting. It is the Kubo oscillator, an oscillator with a random frequency. It is a case of multiplicative noise, but with a complex variable. 

In Stratonovich stochastic calculus, its equation is:

.. math::

   \dot{a}=ia\zeta(t)

Given the initial condition that :math:`a(0)=1`, each trajectory has the solution:

.. math::

    a\left(t\right)=e^{iw(t)}

where

.. math::

    w(t)=\int_{0}^{t}\zeta(\tau)d\tau

The corresponding mean value is different to the instantaneous trajectory, owing to dephasing:

.. math::

    \left\langle a\left(t\right)\right\rangle =e^{-\left\langle w^{2}(t)\right\rangle /2}=e^{-t/2}.

Kubo initial conditions and derivative
--------------------------------------

Here more parameters are needed. One real noise term is required per integration point, specified using :attr:`noises`. Next, the ensemble numbers are required. Here we use 100 vector-level trajectories, and 16 sets at a higher level. In these calculations, the mean amplitude is calculated, and compared against a comparison function.

::

    function e = Kubo()
        p.name = 'Kubo oscillator';
        p.ensembles = [400,16,1];
        p.initial = @(rv,p) 1+0*rv;
        p.deriv = @(a,w,p) i*w.*a;
        p.olabels = {'<a_1>'};
        p.compare{1} = @(t,~) exp(-t/2);
        e = xspde(p);
    end

Kubo error results are reported as:

::

    -  Max sampling error = 1.065936e-02
    -  Max step error = 5.072889e-04
    -  Max comparison difference = 1.269069e-02

Note that these are generally consistent with the graphs below, as they should be.

Is the actual error always less than the reported maximum standard deviation? This is not always the case, for statistical reasons. The statistical estimates given are best estimates of the standard deviations of the plotted means. However, given a large enough number of means at different times, some **must** fall outside the range of a unit standard deviation.

The different time points in the Kubo oscillator trajectories become uncorrelated after a time of order one. Hence an occasional excursion with an error of :math:`2\sigma` can occur.  In other words, the expected maximum sampling error is a multiple of the standard deviation, which should therefore be treated with some caution as a guide to statistical errors.

We see evidence here the sampling errors often exceed the step-size errors, unless large sample numbers are used.

Kubo graphs
-----------

With this choice of algorithm and step-size, the results of a simulation run are plotted below.

.. figure:: Kubo/Kubo1.*

   Kubo oscillator mean amplitude

.. figure:: Kubo/Kubo2.*

   Kubo oscillator amplitude errors

There are some interesting features here. The two solid lines indicate the sampling error.  The error bars indicate the step-size error.  This affects both results, but is only visible in the error graphs, which have an expanded scale.

.. rubric:: Exercise

Add a detuning of :math:`ia` to the differential equation, modify the exact solution to suit, then replot.


Soliton
=======

The third example is the soliton equation for the nonlinear Schrödinger
equation, with:

.. math::

    \frac{da}{dt}=\frac{i}{2}\left[\nabla^{2}a-a\right]+ia\left|a\right|^{2}

Together with the initial condition that :math:`a(0,x)=sech(x)`, this
has an exact solution that doesn’t change in time:

.. math::

   a(t,x) = sech(x)

The Fourier transform at :math:`k=0` is simply:

.. math::

   \tilde{a}(t,0) = \frac{1}{\sqrt{2\pi}}\int sech(x)dx=\sqrt{\frac{\pi}{2}}

Soliton parameters and functions
--------------------------------

The important parameters and functions in this case are:

::

    function [e] = Soliton()
        p.name = 'NLS soliton';
        p.dimensions = 2;
        p.initial = @(v,p) sech(p.x);
        p.deriv = @(a,~,p) i*a.*(conj(a).*a);
        p.linear = @(p) 0.5*i*(p.Dx.^2-1.0);
        p.olabels = {'a_1(x)'};
        p.compare{1}= @(t,~) 1;
        e = xspde(p);
    end

The output reflects the known analytic result.

Soliton graphs and errors
-------------------------

Graphs of results are given below.

.. figure:: Soliton/Soliton1.*

   Soliton amplitude versus space and time

.. figure:: Soliton/Soliton2.*

   Soliton amplitude errors at center

The xgraph program reports that comparison errors are slightly less than the step error,
but this is not always the case, because the error checking does not check errors due to the lattice sizes. In general this needs to be carried out manually.

.. rubric:: Exercise

Add an additive complex noise of :math:`0.01(dw_{1}+idw_{2}`) to the differential equation, then replot with an average over 1000 samples.


Gaussian with HDF5 files
========================

The fifth example is free diffraction of a Gaussian wave-function in three dimensions, given by

.. math::

    \frac{da}{dt}=\frac{i}{2}\nabla^{2}a

Together with the initial condition that :math:`a(0,x)=exp(-\left|\mathbf{x}\right|^{2}/2)`, this has an exact solution for the diffracted intensity in either ordinary space or momentum space:

.. math::

   \begin{aligned}
   \left|a\left(t,\mathbf{x}\right)\right|^{2} & = \frac{1}{\left(1+t^{2}\right)^{3/2}}exp(-\left|\mathbf{x}\right|^{2}/\left(1+t^{2}\right))\\
   \left|\tilde{a}\left(t,\mathbf{k}\right)\right|^{2} & = exp(-\left|\mathbf{k}\right|^{2})\end{aligned}

Gaussian inputs
---------------

Before running this simulation, be careful to change the Matlab working directory to your intended working directory, which must have write permission enabled. For example, type:
 
::

    cd ~  
    
    
A  possible user set of parameters to simulate this is:

::

    function [e] = Gaussian()
        p.dimensions = 4;
        p.initial = @(~,p) exp(-0.5*(p.x.^2+p.y.^2+p.z.^2));
        p.deriv = @(a,~,~) zeros(size(a));
        p.linear = @(p) 1i*0.05*(p.Dx.^2+p.Dy.^2+p.Dz.^2);
        p.observe = {@(a,~) a.*conj(a)};
        p.olabels = '|a(x)|^2';
        p.file = 'Gaussian.h5';
        p.images = 4;
        p.imagetype = 1;
        p.transverse = 2;
        p.headers = 1;
        p.compare{1} = @(t,~) [1+(t/10).^2].^(-3/2);
        [e,in] = xsim(p);
        e = e+xgraph(p.file);
    end

Here the program writes an HDF5 data file using :func:`xsim`, and then reads it in with the stored file-name, using :func:`xgraph`. Note that :func:`xsim` may have to change the file-name to avoid overwriting any old data. In this case, it returns the new file-name is uses. The program reports the following maximum step-size errors, which in this case are negligible, as they are around :math:`\sim10^{-15}`, and are purely due to the interaction picture transformations. These errors do not depend on step-size, apart from rounding.

However, the finite spatial lattice size introduces finite errors in the on axis intensity, in coordinate space. This shows up in the comparison errors.

Gaussian graphs
---------------

With this choice of algorithm and step-size, the results of a simulation run are plotted below. The errors, of order :math:`10^{-7}`, are simply due to interference of diffracted waves caused by the periodic boundary conditions. This is sometimes called aliasing error.  One can think of this physically as being a simulation of an infinite array or periodically repeated Gaussian inputs, which can diffract and interfere.

.. figure:: Gaussian/Gaussian1.*

   Image of transverse gaussian intensity at :math:`t=0`.

.. figure:: Gaussian/Gaussian2.*

   Gaussian intensity diffraction

.. figure:: Gaussian/Gaussian4.*

   Gaussian intensity at :math:`\boldsymbol{r}=0`.

.. figure:: Gaussian/Gaussian5.*

   Gaussian, modulus-squared errors at :math:`\boldsymbol{r}=0` .

.. rubric:: Exercise

Add an additive complex noise of :math:`0.01(dw_{1}+idw_{2}`) to the Gaussian differential equation, then replot with an average over 10 samples.


Planar noise
============

The fifth example is growth of thermal noise of a two-component complex field in a plane, given by the equation

.. math::

    \frac{d\boldsymbol{a}}{dt}=\frac{i}{2}\nabla^{2}\boldsymbol{a}+\boldsymbol{\zeta}(t,x)

where :math:`\boldsymbol{\zeta}` is a delta-correlated complex noise vector field:

.. math::

    \zeta_{j}(t,\mathbf{x})=\left[\zeta_{j}^{re}(t,\mathbf{x})+i\zeta_{j}^{im}(t,\mathbf{x})\right]/\sqrt{2},

with the initial condition that the initial noise is delta-correlated in position space

.. math::

    a(0,\mathbf{x})=\boldsymbol{\zeta}^{(in)}(\boldsymbol{x})

where:

.. math::

    \boldsymbol{\zeta}^{(in)}(\boldsymbol{x})=\left[\boldsymbol{\zeta}^{re(in)}(\mathbf{x})+i\boldsymbol{\zeta}^{im(in)}(\mathbf{x})\right]/\sqrt{2}

This has an exact solution for the noise intensity in either ordinary space or momentum space:

.. math::

   \begin{aligned}
   \left\langle \left|a_{j}\left(t,\mathbf{x}\right)\right|^{2}\right\rangle  & = (1+t)/\Delta V\\
   \left\langle \left|\tilde{a}_{j}\left(t,\mathbf{k}\right)\right|^{2}\right\rangle  & = (1+t)/\Delta V_{k}\\
   \left\langle \tilde{a}_{1}\left(t,\mathbf{k}\right)\tilde{a}_{2}^{*}\left(t,\mathbf{k}\right)\right\rangle  & = 0
   \end{aligned}

Here, the noise is delta-correlated, and :math:`\Delta V`, :math:`\Delta V_{k}` are the cartesian space and momentum space lattice cell volumes respectively. Suppose that :math:`N=N_{x}N_{y}` is the total number of spatial points, and :math:`V=R_{x}R_{y}`, where there are :math:`N_{x(y)}` points in the x(y)-direction, with a total range of :math:`R_{x(y)}`. Then, :math:`\Delta x=R_{x}/N_{x}` ,\ :math:`\Delta k_{x}=2\pi/R_{x}` , so that:

.. math::

   \begin{aligned}
   \Delta V & = \Delta x\Delta y=\frac{V}{N}\\
   \Delta V_{k} & = \Delta k_{x}\Delta k_{y}=\frac{(2\pi)^{2}}{V}.
   \end{aligned}

In the simulations, two planar noise fields are propagated, one using noise generated in position space, the other with noise generated in momentum space. This example shows that, provided no filters are applied, both types of noise are identical in their effects. However, momentum space noise uses an internal N-dimensional inverse FFT before being added, which is slower, so this method is not recommended unless needed.

Planar inputs
-------------

::

    function [e] = Planar()
        p.name = 'Planar noise growth';
        p.dimensions = 3;
        p.fields = 2;
        p.ranges = [1,5,5];
        p.steps = 2;
        p.noises = [2,2];
        p.ensembles = [10,2,2];
        p.initial = @Initial;
        p.deriv = @D_planar;
        p.linear = @Linear;
        p.observe{1} = @(a,p) Int(a(1,:).*conj(a(1,:)),p);
        p.observe{2} = @(a,p) Int(a(2,:).*conj(a(2,:)),p.dk,p);
        p.observe{3} = @(a,p) Ave(a(1,:).*conj(a(2,:)));
        p.transforms = {[0,0,0],[0,1,1],[0,1,1]};
        p.olabels{1} = '<\int|a_1(x)|^2 d^2x>';
        p.olabels{2} = '<\int|a_2(k)|^2 d^2k>';
        p.olabels{3} = '<‌<a_1(k)a^*_2(k)>‌>';
        p.compare{1} = @(t,in) [1+t]*p.nspace;
        p.compare{2} = @(t,in) [1+t]*p.nspace;
        p.compare{3} = @(t,in) 0;
        p.images = {4,2,0};
        p.transverse = {2,2,0};
        p.pdimensions = {4,1,1};
        e = xspde(p);
    end
    function a0 = Initial(v,p)
        a0(1,:)  = (v(1,:)+1i*v(2,:))/sqrt(2);
        a0(2,:)  = (v(3,:)+1i*v(4,:))/sqrt(2);
    end
    function da = D_planar(a,w,p)
        da(1,:)  = (w(1,:)+1i*w(2,:))/sqrt(2);
        da(2,:)  = (w(3,:)+1i*w(4,:))/sqrt(2);
        end
    function L = Linear(p)
        lap = p.Dx.^2+p.Dy.^2;
        L(1,:)  = 1i*0.5*lap(:);
        L(2,:)  = 1i*0.5*lap(:);
    end

Planar graphs
-------------

With this choice of algorithm and step-size, the results are plotted below.

.. _fig-Planar-noise-intensity-image:
.. figure:: Planar/Planar1.*

   Planar noise intensity as a transverse slice in the :math:`t=1`, :math:`y=0` plane. The relatively large sampling error is because there are not many samples.

.. figure:: Planar/Planar2.*

   Growth in noise intensity with time vs. :math:`x`, at :math:`y=0`.

.. figure:: Planar/Planar3.*

   Growth in planar noise intensity at :math:`x=y=0`, vs. exact results.

.. _fig-Errors-in-planar:
.. figure:: Planar/Planar4.*

   Errors in planar noise intensity at :math:`x=y=0`, vs. exact results. These results are averaged across the plane, as well as being ensemble averaged.

.. figure:: Planar/Planar5.*

   Growth in planar noise intensity in momentum space, for the second field, at :math:`k_{x}=k_{y}=0`.

.. _Errors-in-planar-1:
.. figure:: Planar/Planar6.*

   Lattice averaged errors in cross-correlations in momentum space, vs. exact results.

.. rubric:: Exercise

Add a decay rate of :math:`-a` to the Planar differential equation, then replot.


Extensible simulations
======================

Next, an extensible simulation: first a noisy absorber, then a noisy amplifier.  The second part has a different differential equation, and larger graphical scales.

This is handled with the extensibility feature of xSPDE. Just enter a sequence of inputs, in the form ``{in1, in2, in3, ...}`` with a corresponding sequence of graphs, ``{g1, g2, g3m ...}``. Here, the first equation is:

.. math::

    \frac{da}{dt}=-a+\zeta_{1}(t)+i\zeta_{2}(t)

with an initial condition of :math:`a=1`. The mean intensity is constant:

.. math::

    \left\langle \left|a(t)\right|^{2}\right\rangle = 1.

Input file
----------

The full input file is given below.

::

    function [e] = Gain()
        p.name = 'Loss with noise';
        p.ranges = 4;
        p.noises = [2,0];
        p.ensembles = [100,16,1];
        p.initial = @(v,~) (v(1,:)+1i*v(2,:))/sqrt(2);
        p.deriv = @(a,w,p) -a + w(1,:)+1i*w(2,:);
        p.observe{1} = @(a,~,~) a.*conj(a);
        p.olabels = {'|a|^2'};
        p.compare = {@(t,~) 1+0*t};
        in2 = in;
        p2.steps = 4;
        p2.origin = p.ranges;
        p2.name = 'Gain with noise';
        p2.deriv = @(a,z,p) a + z(1,:)+1i*z(2,:);
        p2.compare = {@(t,~) 2*exp(2*(t-4))-1};
        e = xspde({in,in2});
    end

Note that the code defines ``in2 = in`` before making any changes, so that only a few additional inputs are needed. The number of :attr:`steps` is increased to improve the accuracy of the second integration, and the second time origin is chosen so that it starts from the time the first simulation is completed.

Results are graphed below.

.. figure:: Gain/Gain1.*

   Absorber intensity

Comparison graphs are also produced for the relative errors. In the graph given here,

Extended simulations
--------------------

The second differential equation has an initial condition corresponding to the solution of the first equation at :math:`t=4`, and the derivative:

.. math::

    \frac{da}{dt}=a+\zeta_{1}(t)+i\zeta_{2}(t)

The mean intensity grows exponentially:

.. math::

    \left\langle \left|a\right|^{2}\right\rangle =1.

.. math::

    \left\langle \left|a(t)\right|^{2}\right\rangle =2e^{2(t-4)}-1

 where

.. math::

    w(t)=\int_{0}^{t}\zeta(t^\prime)dt^\prime

To compare the calculated solution with this exact result, there are two :attr:`compare` functions in the project file. The time axis in the second graph has the origin reset to zero.

.. figure:: Gain/Gain3.*

   Noisy amplifier intensity

Comparison graphs of the relative errors are also produced here as well.

.. figure:: Gain/Gain4.*

   Noisy amplifier intensity errors, showing how the sampling errors
   increase in time.

.. rubric:: Exercise

Reverse the order of gain and loss.


Characteristic
==============

The next example is the characteristic equation for a traveling wave at constant velocity,

.. math::

    \frac{da}{dt}+\frac{da}{dx}=0

Together with the initial condition that :math:`a(0,x)=sech(2x+5)`, this has an exact solution that propagates at a constant velocity:

.. math::

   a(t,x) = sech(2(x-t)+5)

The time evolution at :math:`x=0` is simply:

.. math::

   a(t,0) = sech(2(t-5/2))

Characteristic inputs
---------------------

The important parameters and functions in this case are:

::

    function [e] = Characteristic()
        p.name = 'Characteristic'
        p.dimensions = 2;
        p.initial = @(~,p) sech(2.*(p.x+2.5));
        p.deriv = @(a,~,p) 0*a;
        p.linear = @(p) -p.Dx;
        p.olabels = {'a_1(x)'};
        p.compare = {@(t,in) sech(2.*(t-2.5))};
        e = xspde(p);
    end

The simulation program reports step errors of order of the intrinsic rounding error, which is slightly misleading, since while the interaction picture is essentially exact, it is solving a finite lattice problem exactly. This transverse lattice discretization does introduce transverse discretization errors in addition, and these are seen from the comparisons with the exact results. The lesson to be learnt here is that one must check the transverse discretization errors in addition, by changing the transverse lattice.

Graphs of results are given below.

.. figure:: Characteristic/Characteristic1.*

   Characteristic traveling wave versus space and time

.. figure:: Characteristic/Characteristic2.*

   Characteristic errors at center

.. rubric:: Exercise

Recalculate with the opposite velocity, and a new exact solution.


Equilibrium
===========

We now move on to frequency space simulations. The equation is the same as the earlier loss equation, that is

.. math::

    \frac{da}{dt}=-a+\zeta(t)

where :math:`\zeta(t)=\zeta_{1}(t)+i\zeta_{2}(t)`, with an initial condition of :math:`a=(w_{1}+iw_{2})/\sqrt{2}`. For sufficiently long time-intervals, the solution is given by:

.. math::

    \tilde{a}\left(\omega\right)=\frac{\tilde{\zeta}(\omega)}{1-i\omega}

The expectation value of the noise Fourier transform modulus squared, in the large :math:`T` limit, is therefore:

.. math::

   \begin{aligned}
   \left\langle \left|\tilde{a}(\omega)\right|^{2}\right\rangle  & = \frac{1}{2\pi\left(1+\omega^{2}\right)}\int\int e^{i\omega(t-t')}\left\langle \zeta(t)\zeta^{*}(t')\right\rangle dtdt'\,.\\
    & =  \frac{T}{\pi\left(1+\omega^{2}\right)}\end{aligned}

Program inputs
--------------

The full input file is given below.

::

    function e = Equilibrium()
        p.name = 'Equilibrium spectrum';
        p.points = 640;
        p.ranges = 100;
        p.noises = [2,0];
        p.ensembles = [100,1,10];
        p.initial = @(v,~) (v(1,:)+1i*v(2,:))/sqrt(2);
        p.deriv = @(a,z,p) -a + z(1,:)+1i*z(2,:);
        p.observe{1} =@(a,~) a.*conj(a);
        p.observe{2} =@(a,~) a.*conj(a);
        p.transforms ={0,1};
        p.olabels = {'|a(t)|^2', '|a(w)|^2'};
        p.compare = {@(t,~) 1.+0*t, @(w,~)100.16./(pi*(1+w.^2))};
        e = xspde(p);
    end

Results are graphed below. The calculated spectrum is indistinguishable from the exact result.

.. figure:: Equilibrium/Equilibrium1.*

   Equilibrium spectral intensity

The xsim program will report in the error summary that the comparison differences indicate that the maximum error reported is typically about 1.5 standard deviations of the maximum sampling error.  Given the number of data points, this is a reasonable result: statistical errors can exceed one standard deviation.

.. rubric:: Exercise

Add a second field coupled to the first, so that:

.. math::

   \begin{aligned}
   \frac{da}{dt} & = -a+\zeta(t)\\
   \frac{db}{dt} & = -b+a
   \end{aligned}

Compare the two spectra, and calculate what the second one should look like.
